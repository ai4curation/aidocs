{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AI Guide","text":"<p>This site will grow into a collection of how-tos and reference guides for curators and maintainers of knowledge bases to integrate AI into their workflows.</p> <p>The aim here is to provide practical guides that can be immediately integrated into existing curation workflows. This means things like:</p> <ul> <li>agents that plug into the existing GitHub repos that curators and ontology editors use,   empowered to make changes to curated artefacts</li> <li>plugins for existing chat UIs</li> </ul>"},{"location":"how-tos/instruct-github-agent/","title":"AI Instructors Guide: GitHub Agents","text":"<p>This is a guide for instructing the AI agent that lives in GitHub repo. This assumes your AI controller has set up GitHub actions in your repo.</p>"},{"location":"how-tos/instruct-github-agent/#how-it-works","title":"How it works","text":""},{"location":"how-tos/instruct-github-agent/#graphical-overview","title":"Graphical Overview","text":""},{"location":"how-tos/instruct-github-agent/#how-to-use-it","title":"How to use it","text":""},{"location":"how-tos/instruct-github-agent/#invocation","title":"Invocation","text":"<p>The AI agent is invoked by an exact string such as <code>@dragon-ai-agent please</code> (check your local repo documentation). Anything that follows as well as other content from the issue/PR is passed to the AI.</p> <p>The AI has tools to read the issue/PR, as well as follow up on any linked issues/PRs.</p> <p>Note: the string <code>please</code> has to follow exactly. This part is deterministic, it is not an AI that controls the invocation. The choice of \"please\" is not just about politeness, we need a special keyword to avoid accidental invocation.</p>"},{"location":"how-tos/instruct-github-agent/#authorization","title":"Authorization","text":"<p>Note that the agent will NOT respond to you if you are not an authorized controller.</p> <p>To check if you are authorized, see the file  <code>~/.github/ai-controllers.json</code>. </p> <p>You can make a PR on this to add yourself (be sure to follow JSON syntax), but check with your repo maintainer first for local procedures.</p>"},{"location":"how-tos/instruct-github-agent/#ai-system-instructions","title":"AI system instructions","text":"<p>See the file <code>~/CLAUDE.md</code> in the top level of the repo. Other AI applications may use different files -- for example, goose uses <code>~/.goosehints</code>, but these will typically be symlinked.</p> <p>The instructions are in natural language and should be equally readable by humans or AI.</p> <p>More advanced users should feel free to make PRs on this file</p>"},{"location":"how-tos/instruct-github-agent/#tools-usable-by-the-ai","title":"Tools usable by the AI","text":"<p>Depending on what AI host runner is used, the configuration file that controls which agents are available may be in different places.</p> <ul> <li>For claude code, this will be in <code>.claude/settings.json</code></li> <li>For goose, this will be in <code>.config/goose/config.yaml</code></li> </ul>"},{"location":"how-tos/instruct-github-agent/#prompting-guide","title":"Prompting guide","text":""},{"location":"how-tos/instruct-github-agent/#start-simple","title":"Start Simple","text":"<p>For a first task, find an issue that is very straightforward, where the user has done the bulk of the \"thinking\" work, and the issue is fairly rote and mechanical.</p> <p>Go to the issue you want resolved and make a new comment and say</p> <pre><code>@dragon-ai-agent please resolve this issue\n</code></pre> <p>You can also add your own commentary - for example, if the original issue isn't completely clear or is missing key information the AI is not likely to infer.</p> <p>For example:</p> <pre><code>@dragon-ai-agent please resolve this issue, making sure the term has a parent\n</code></pre>"},{"location":"how-tos/instruct-github-agent/#deep-research","title":"Deep Research","text":"<p>You can always ask the AI to do a background research on an issue. We are exploring the best tools to use for Deep Research, in the interim, the AI has access to basic web search tools which are good enough for many purposes.</p> <p>One usage pattern is to find an issue that depends on a lot of cutting edge science and to ask the AI to do background reading on the subject (you can ask it to hold off on implementing anything)</p> <p>An example:</p> <pre><code>@dragon-ai-agent please help us resolve this issue, we are unsure how to proceed,\nplease read the latest literature on the topic\n</code></pre>"},{"location":"how-tos/instruct-github-agent/#accessing-pmids","title":"Accessing PMIDs","text":"<p>The AI should be able to download and read full text for a subset of PMIDs (including those on PMC). Currently we are exploring the best tools to use, so be aware there may be some temporary limitations, such as not being able to view images.</p> <p>THe prompt the AI receives should tell it to use PMIDs as provenance (e.g. in definitions, in synonyms), but we are still figuring the best way to prompt, and you might need to occasionally give more detailed instructions.</p>"},{"location":"how-tos/instruct-github-agent/#complex-refactoring-tasks","title":"Complex refactoring tasks","text":"<p>The AI is capable of writing ad-hoc code to perform certain kinds of tasks. This is generally easier when the source of the ontology is in obo format. For some more complex tasks, the AI may not have been provided with the right tools or software libraries.</p> <p>Examples:</p> <ul> <li>https://github.com/obophenotype/uberon/issues/3548</li> </ul>"},{"location":"how-tos/instruct-github-agent/#tuning-the-ai","title":"Tuning the AI","text":"<p>You can make PRs on the <code>CLAUDE.md</code> or equivalent to add new instructions.</p>"},{"location":"how-tos/instruct-github-agent/#magic-keywords","title":"Magic keywords","text":"<p>If your repo admin has set up your agent to use an Claude code, then some keywords deterministically trigger more detailed chain of thought thinking:</p> <ul> <li>\"think hard\"</li> <li>\"ultrathink\"</li> </ul> <p>We are stil investigation equivalent behavior in other AI apps.</p> <p>See this guide for some tips on using Claude.</p> <p>Even if there are no deterministic triggers, in general, it can help to tell the AI to think longer or harder on tasks that require additional effort.</p>"},{"location":"how-tos/instruct-github-agent/#be-respectful-of-the-user-who-created-the-issue","title":"Be respectful of the user who created the issue","text":"<p>Different issue trackers have different user communities - for some, requests come in entirely from the curator community, others may have broader users.</p> <p>While the core curator community who uses the issue tracker should be educated in how the tracker is used (including the use of AI), users from outside this community may not be aware - and some of these people may not like having their request seemingly handled by an AI, so use situational awareness in when to invoke AI.</p>"},{"location":"how-tos/instruct-github-agent/#learning-more","title":"Learning More","text":""},{"location":"how-tos/instruct-github-agent/#local-experimentation","title":"Local experimentation","text":""},{"location":"how-tos/instruct-github-agent/#troubleshooting","title":"Troubleshooting","text":""},{"location":"how-tos/instruct-github-agent/#timeouts","title":"Timeouts","text":"<p>If you ask the AI to do a task that is long running, there is more chance that either the action will time out, or the running of the AI app within the action will hit a limit.</p> <p>If your repo is configured to use cborg.lbl.gov as a proxy, then a known issue is timeouts.</p> <p>Timeouts might not be obvious - by their nature, they time out before providing an update on the issue. The only way to debug is to go to the \"actions\" tab in GitHub and debug from there.</p> <p>If you have a task that is likely to be long running - for example, if you want the AI to updates 100s of terms - you might want to try asking the AI to make an initial PR after doing only a dozen or so, and then iterate.</p>"},{"location":"how-tos/instruct-github-agent/#debugging-actions","title":"Debugging Actions","text":"<p>You can go to the \"actions\" tab in GitHub, and look for the job that was triggered by your invocation. Clicking on this will show you a full log. There may be a lot of information here - using ChatGPT can help you debug. Usually it helps to scroll to the end and see the most recent messages to have a clue about what went wrong.</p>"},{"location":"how-tos/instruct-github-agent/#running-out-of-credits","title":"Running out of credits","text":"<p>Different repos may be configured in different ways for recharging credits. Typically things will be set up such that a proxy is used (e.g. cborg.lbl.gov) with an API key tied to a project code.</p> <p>In general you should ask the AI admin for your repo if you see messages that credit is too low.</p>"},{"location":"how-tos/integrate-ai-into-your-kb/","title":"How to integrate AI into your Knowledge Base","text":"<p>This is a high level advanced guide for maintainers of knowledge bases with some high level pointers on how to start effectively using AI to enhance curation.</p>"},{"location":"how-tos/integrate-ai-into-your-kb/#tip-1-no-fancy-frameworks-needed-just-simple-mcps-or-command-line-tools","title":"Tip 1: No fancy frameworks needed - just simple MCPs or command line tools","text":"<p>Intimidated by the growing number of agent frameworks? Don't worry, you don't need most of these.</p> <p>All you really need are a handful of simple MCP servers or command line tools. These can be hooked up to generic frameworks.</p> <p>The command line tools could be wrapped in a Docker container; this is the strategy for ODK-AI.</p> <p>You should rely on existing tools for doing things like literature search - you only need to write MCPs that are specific to read/write/validation on your KB.</p> <p>This is much easier if you follow O3 guidelines and manage your content in GitHub. In fact if your content is small enough, you might not need any new tools!</p>"},{"location":"how-tos/integrate-ai-into-your-kb/#tip-2-keep-ai-instructions-checked-in-at-the-root-of-your-github-repo","title":"Tip 2: Keep AI instructions checked in at the root of your GitHub repo","text":"<p>Examples:</p> <ul> <li>CLAUDE.md in Uberon repo</li> </ul>"},{"location":"how-tos/integrate-ai-into-your-kb/#tip-3-train-curators-to-use-simple-tool-enabled-ai-applications-eg-goose","title":"Tip 3: Train curators to use simple tool-enabled AI applications (e.g Goose)","text":"<p>Many AI hosts such as Claude Code or various VS code plugins are suboptimal for non-technical users. AI applications such as Claude Desktop may be better, but currently it's hard to configure.</p> <p>At the time of writing, we recommend Goose as an AI app/host, due to these features:</p> <ul> <li>Ease of configuring MCPs</li> <li>Choice of either Desktop version (for non-devs) or Command Line (for devs)</li> <li>Ability to use multiple models including proxies.</li> </ul> <p>See the Installation Guide</p> <p>As an example, this video shows how to configure:</p>"},{"location":"how-tos/integrate-ai-into-your-kb/#set-up-github-actions","title":"Set up GitHub actions","text":"<p>See some of the actions in this org. Again this works best if your content is managed according to O3 guidelines.</p>"},{"location":"how-tos/integrate-ai-into-your-kb/#document-and-train","title":"Document and Train","text":""},{"location":"how-tos/integrate-ai-into-your-kb/#continuous-evaluation","title":"Continuous evaluation.","text":""},{"location":"how-tos/set-up-github-actions/","title":"How to create an AI agent for GitHub actions","text":"<p>This assumes that you are already using GitHub as your source of truth for content, O3-guidelines style.</p> <p>It also assumes you have some familiarity with GitHub actions, and have basic QC actions set up. If you are managing an ODK-compliant repo this is certainly the case.</p>"},{"location":"how-tos/set-up-github-actions/#set-up-aiyml","title":"Set up <code>ai.yml</code>","text":"<p>This might look something like this:</p> <p>https://github.com/monarch-initiative/mondo/blob/master/.github/workflows/ai-agent.yml</p> <pre><code>name: Dragon AI Agent GitHub Mentions\n\non:\n  issues:\n    types: [opened, edited]\n  issue_comment:\n    types: [created, edited]\n  pull_request:\n    types: [opened, edited]\n  pull_request_review_comment:\n    types: [created, edited]\n\njobs:\n  check-mention:\n    runs-on: ubuntu-latest\n    outputs:\n      qualified-mention: ${{ steps.detect.outputs.qualified-mention }}\n      prompt: ${{ steps.detect.outputs.prompt }}\n      user: ${{ steps.detect.outputs.user }}\n      item-type: ${{ steps.detect.outputs.item-type }}\n      item-number: ${{ steps.detect.outputs.item-number }}\n      controllers: ${{ steps.detect.outputs.controllers }}\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n\n      - name: Detect AI mention\n        id: detect\n        uses: dragon-ai-agent/github-mention-detector@v1.0.0\n        with:\n          github-token: ${{ secrets.PAT_FOR_PR }}\n          fallback-controllers: 'cmungall'\n\n  respond-to-mention:\n    needs: check-mention\n    if: needs.check-mention.outputs.qualified-mention == 'true'\n    permissions:\n      contents: write\n      pull-requests: write\n      issues: write\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n          token: ${{ secrets.PAT_FOR_PR }}\n\n      - name: Respond with AI Agent\n        uses: dragon-ai-agent/run-goose-obo@v1.0.4\n        with:\n          anthropic-api-key: ${{ secrets.ANTHROPIC_API_KEY }}\n          openai-api-key: ${{ secrets.CBORG_API_KEY }}\n          github-token: ${{ secrets.PAT_FOR_PR }}\n          prompt: ${{ needs.check-mention.outputs.prompt }}\n          user: ${{ needs.check-mention.outputs.user }}\n          item-type: ${{ needs.check-mention.outputs.item-type }}\n          item-number: ${{ needs.check-mention.outputs.item-number }}\n          controllers: ${{ needs.check-mention.outputs.controllers }}\n          agent-name: 'Dragon-AI Agent'\n          branch-prefix: 'dragon_ai_agent'\n          robot-version: 'v1.9.7'\n</code></pre> <p>This assumes using goose-ai-obo-action</p>"},{"location":"how-tos/set-up-github-actions/#set-up-repository-secrets","title":"Set up repository secrets","text":"<p>The URL should be something like <code>https://github.com/monarch-initiative/mondo/settings/secrets/actions</code></p> <p>A typical setup might include:</p> <ul> <li><code>ANTHROPIC_API_KEY</code></li> <li><code>CBORG_API_KEY</code></li> <li><code>PAT_FOR_PR</code></li> </ul> <p>The key names will correspond to what you have in the action.yml above</p>"},{"location":"how-tos/set-up-github-actions/#configure-the-agent-including-default-mcps","title":"Configure the agent, including default MCPs","text":"<p>Create a folder <code>.config/goose</code> with a file <code>config.yaml</code>.</p> <p>Examples:</p> <ul> <li>.config/goose for Mondo</li> </ul> <p>Here is an example:</p> <pre><code>OPENAI_HOST: https://api.cborg.lbl.gov\nOPENAI_BASE_PATH: v1/chat/completions\nGOOSE_MODEL: anthropic/claude-sonnet\nGOOSE_PROVIDER: openai\nextensions:\n  developer:\n    bundled: true\n    display_name: Developer\n    enabled: true\n    name: developer\n    timeout: 300\n    type: builtin\n  git:\n    args:\n    - mcp-server-git\n    bundled: null\n    cmd: uvx\n    description: Git version control system integration\n    enabled: false\n    env_keys: []\n    envs: {}\n    name: git\n    timeout: 300\n    type: stdio\n  memory:\n    bundled: true\n    display_name: Memory\n    enabled: true\n    name: memory\n    timeout: 300\n    type: builtin\n  owlmcp:\n    args:\n    - owl-mcp\n    bundled: null\n    cmd: uvx\n    description: ''\n    enabled: false\n    env_keys: []\n    envs: {}\n    name: owlmcp\n    timeout: 300\n    type: stdio\n  pdfreader:\n    args:\n    - mcp-read-pdf\n    bundled: null\n    cmd: uvx\n    description: Read large and complex PDF documents\n    enabled: false\n    env_keys: []\n    envs: {}\n    name: pdfreader\n    timeout: 300\n    type: stdio\n</code></pre> <p>The <code>extensions</code> section is the default MCP plugins. </p> <p>This setup is configured to use Anthropic claude-sonnet via a LiteLLM proxy (CBORG):</p> <pre><code>OPENAI_HOST: https://api.cborg.lbl.gov\nOPENAI_BASE_PATH: v1/chat/completions\nGOOSE_MODEL: anthropic/claude-sonnet\nGOOSE_PROVIDER: openai\n</code></pre> <p>You can use a similar setup for your own LiteLLM proxy if you have one. Note if you find this complex, please upvote this issue.</p> <p>Things are easier if you just want to talk straight to a provider like Anthropic, no proxy, all you need is <code>GOOSE_MODEL</code>. But note this likely means you are using a person API key. Be aware that agentic AI usage can be costly.</p>"},{"location":"how-tos/set-up-github-actions/#set-up-goosehints","title":"Set up .goosehints","text":"<p>For many of my repos, I have a <code>CLAUDE.md</code> and I symlink <code>.goosehints</code> to that, because I am too lazy to write different instructions for different agents. In practice it might be better to tune instructions.</p> <p>What you put in there depends on your own use case. Do careful evals if you can't, but otherwise do vibe tests and iterate.</p> <p>Some examples here:</p> <ul> <li>CLAUDE.md on Mondo</li> </ul>"},{"location":"tutorials/ontology-editing-with-ai/","title":"Using local AI tools","text":"<p>This tutorial walks through how to use AI tools locally. This is aimed at mostly non-technical editors of OBO ontologies that have adopted standardized ODK workflows. There are some technical steps required but these should be straightforward. This will work best with a Mac or Linux.</p>"},{"location":"tutorials/ontology-editing-with-ai/#background","title":"Background","text":"<p>Most people have by now used web-based chat interfaces such as ChatGPT, or more powerful deep research models (o3, Perplexity Deep Research). These can now take advantage of information online as well as what is already \"known\" by the model. However, they can't interface with files and tools that you might have locally, e.g.</p> <ul> <li>your local copy of the ontology edit file, checked out from GitHub</li> <li>Protege</li> <li>Reasoners</li> <li>Validation/QC workflows</li> </ul> <p>Agentic AI is a paradigm where an AI application can make use of tools to achieve some objective. For ontology editing, this might be tools to edit the ontology or run a reasoner or workflow. These tools could include command line tools (e.g what you have available via ODK), or tools made available via the Model Context Protocol</p> <p>There are a growing number of general-purpose applications that allow for easy plug and play of different tools. Many of these are aimed at developers, and hook into existing Integrated Development Environments (IDEs). These are not ideal for non-technical users.</p> <p>Two of the main easy-to-use Desktop applications are Claude Desktop (not to be confused with Claude Code, or the web interface to Claude) and Goose. We focus here on Goose, as it allows for easy configurability</p>"},{"location":"tutorials/ontology-editing-with-ai/#install-goose","title":"Install Goose","text":"<p>Go to the install page for Goose. Choose the Desktop app (more ambitious or technical users may want to also install the CLI app)</p>"},{"location":"tutorials/ontology-editing-with-ai/#set-up-your-llm","title":"Set up your LLM","text":"<p>Select settings/advanced, and select a Model. We recommend Anthropic/Claude Sonnet. You will need an API key. We recommend speaking to your supervisor about getting an API key that is charged to a project you work on.</p>"},{"location":"tutorials/ontology-editing-with-ai/#try-it-out","title":"Try it out","text":"<p>You should be able to use the UI the same way as a normal AI chat, try asking some questions about your favorite topics.</p> <p>However, you can do more here, including with local files. Try giving it a folder full of PDFs and asking it to list the contents. Try finding a particular PDF, and then asking it to summarize it.</p>"},{"location":"tutorials/ontology-editing-with-ai/#install-xcode-mac-users","title":"Install xcode (mac users)","text":"<p>In order to use most of the useful features of agents, you will need to certain things installed locally. For macs, this means installing Xcode:</p> <ul> <li>Xcode</li> </ul> <p>You can just ask Goose to walk you through the installation.</p>"},{"location":"tutorials/ontology-editing-with-ai/#try-it-out-more-advanced-features","title":"Try it out more advanced features","text":"<p>Some things you can try:</p> <ul> <li><code>clone the OBO cell ontology repo from github</code></li> <li><code>create a web page for many ontology</code></li> <li><code>create a web app for annotating single-cell experiments, use the OLS API to implement autocomplete over CL</code></li> </ul>"},{"location":"tutorials/ontology-editing-with-ai/#install-owl-mcp-extension","title":"Install OWL-MCP extension","text":"<p>Next we will try installing an ontology-specific MCP</p> <p>You can either install directly from this link:</p> <ul> <li>\u2b07\ufe0f Install OWL-MCP</li> </ul> <p>Or to do this manually, in the Extension section of Goose, add a new entry for owlmcp:</p> <p><code>uvx owl-mcp</code></p> <p>This video shows how to do this manually:</p>"},{"location":"tutorials/ontology-editing-with-ai/#try-it-out_1","title":"Try it out","text":"<p>You can ask to create an ontology, and add axioms to an ontology. This video walks you through the process end-to-end. We will outline the steps below</p>"}]}